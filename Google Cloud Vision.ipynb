{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print('Texts:')\n",
    "\n",
    "    for text in texts:\n",
    "        print('\\n\"{}\"'.format(text.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_text('img/alberto_dni.JPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Faces detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_faces(path):\n",
    "    \"\"\"Detects faces in an image.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    \n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    response = client.face_detection(image=image)\n",
    "    faces = response.face_annotations\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                       'LIKELY', 'VERY_LIKELY')\n",
    "    print('Faces:')\n",
    "\n",
    "    for face in faces:\n",
    "        print('anger: {}'.format(likelihood_name[face.anger_likelihood]))\n",
    "        print('joy: {}'.format(likelihood_name[face.joy_likelihood]))\n",
    "        print('surprise: {}'.format(likelihood_name[face.surprise_likelihood]))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in face.bounding_poly.vertices])\n",
    "        vertices_int = [(vertex.x,vertex.y) for vertex in face.bounding_poly.vertices]\n",
    "        \n",
    "\n",
    "        print('face bounds: {}'.format(','.join(vertices)))\n",
    "    \n",
    "    x = int(vertices_int[0][0])\n",
    "    y = int(vertices_int[0][1])\n",
    "    width = np.absolute(int(vertices_int[0][0]) - int(vertices_int[1][0]))\n",
    "    height = np.absolute(int(vertices_int[0][1]) - int(vertices_int[2][1]))\n",
    "    return x,y,width,height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,width,height = detect_faces('img/marian_drive.JPG')\n",
    "im = np.array(Image.open('img/marian_drive.JPG'), dtype=np.uint8)\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "\n",
    "rect = patches.Rectangle((x,y),height,width,linewidth=1,edgecolor='r',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "ax.imshow(im)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,width,height = detect_faces('known_people/marian2.JPG')\n",
    "im = np.array(Image.open('known_people/marian2.JPG'), dtype=np.uint8)\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "\n",
    "rect = patches.Rectangle((x,y),height,width,linewidth=1,edgecolor='r',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "ax.imshow(im)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import face_recognition as fk\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(path):return resize(fk.load_image_file(path), (600,800), mode='reflect')\n",
    "def compare(im_array1,im_array2):\n",
    "    try:\n",
    "        encoding1 = fk.face_encodings(im_array1)[0]\n",
    "        encoding2 = fk.face_encodings(im_array2)[0]\n",
    "        return fk.compare_faces([encoding1], encoding2)\n",
    "    except Exception as e:\n",
    "        print(\"Error: %s\" %e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marian,alberto = load('img/marian.JPG'), load('img/alberto.JPG')\n",
    "dni_alberto,driver_marian = fk.load_image_file('img/alberto_dni.JPG'),fk.load_image_file('img/marian_drive.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(driver_marian, marian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
